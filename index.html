<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UniBiDex: Universal Bimanual Dexterous Manipulation</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <!-- Title and Authors -->
        <div class="title-section">
            <h1 class="project-title">UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation</h1>
            <div class="authors">
                <a href="#" class="author">Zhongxuan Li<sup>1,*</sup></a>
                <a href="#" class="author">Zeliang Guo<sup>2,*</sup></a>
                <a href="#" class="author">Jun Hu<sup>2</sup></a>
                <a href="#" class="author">David Navarro-Alarcon<sup>3</sup></a>
                <a href="#" class="author">Jia Pan<sup>1</sup></a>
                <a href="#" class="author">Hongmin Wu<sup>4,†</sup></a>
                <a href="#" class="author">Peng Zhou<sup>2,†</sup></a>
            </div>
            <div class="affiliation">
                <div class="affiliation-line"><sup>1</sup> Department of Computer and Data Science, The University of Hong Kong</div>
                <div class="affiliation-line"><sup>2</sup> Dongguan Key Laboratory of Intelligent Equipment and Smart Industry, School of Advanced Engineering, The Great Bay University</div>
                <div class="affiliation-line"><sup>3</sup> Department of Mechanical Engineering, The Hong Kong Polytechnic University</div>
                <div class="affiliation-line"><sup>4</sup> Guangdong Academy of Sciences</div>
            </div>
            <div class="contribution-note">* Equal contribution, † Corresponding author</div>
            <div class="links">
                <a href="assets/papers/paper.pdf" class="link-button" target="_blank">Paper</a>
                <a href="https://github.com/Dieselmarble/UniBiDex" class="link-button" target="_blank">Code</a>
            </div>
        </div>

        <!-- Hero Video -->
        <section class="hero-video">
            <div class="video-container">
                <video controls width="100%" poster="">
                    <source src="videos/video.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </section>

        <!-- Abstract -->
        <section class="section">
            <h2 class="section-title">Abstract</h2>
            <div class="section-content">
                <p>
                    We present <strong>UniBiDex</strong>, a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VR-based and leader–follower input modalities. UniBiDex enables real-time, contact-rich dual-arm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees.
                </p>
                <p>
                    The framework employs null-space control to optimize bimanual configurations, ensuring smooth, collision-free and singularity-aware motion across tasks. We validate UniBiDex on a long-horizon kitchen-tidying task involving five sequential manipulation subtasks, demonstrating higher task success rates, smoother trajectories, and improved robustness compared to strong baselines.
                </p>
                <p>
                    By releasing all hardware and software components as open-source, we aim to lower the barrier to collecting large-scale, high-quality human demonstration datasets and accelerate progress in robot learning.
                </p>
            </div>
        </section>

        <!-- System Overview -->
        <section class="section">
            <h2 class="section-title">System Overview</h2>
            <div class="section-content">
                <p>
                    The proposed system supports two teleoperation input modalities: VR headsets and leader–follower arms. For the VR mode, we use the Meta Quest 3, while the leader–follower mode is based on the hardware design of the GELLO system. A unified dual-arm control layer minimizes collisions and inverse-kinematics failures in both modes, enabling precise and reliable bimanual manipulation.
                </p>
                
                <h3 class="subsection-title">Framework Architecture</h3>
                <div class="figure-container">
                    <img src="assets/images/framework.png" alt="UniBiDex Framework Architecture" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" />
                </div>
                
                <p>
                    The framework integrates heterogeneous input devices into a shared control stack with consistent kinematic treatment. The name "UniBiDex" reflects two core principles: <strong>universal device support</strong> (any input modality can be integrated) and <strong>unified constraint handling</strong> (all safety and task-related constraints are enforced through a single bimanual control module). The overall architecture consists of four decoupled modules: <em>input preprocessing</em>, <em>motion retargeting</em>, <em>bimanual motion control</em>, and <em>haptic feedback</em>.
                </p>

                <h3 class="subsection-title">Motion Retargeting and Safety-Aware Control</h3>
                <p>
                    To integrate heterogeneous input devices, we define a <em>virtual base frame</em> at the user's initial input pose. All subsequent teleoperation commands are expressed relative to this frame and then retargeted to the robot:
                </p>
                
                <div class="math-formula">
                    <div class="formula-box">
                        <sup>V</sup>ΔT<sub>C<sub>i</sub></sub>(t) = (<sup>V</sup>T<sub>C<sub>i</sub></sub><sup>0</sup>)<sup>-1</sup> <sup>V</sup>T<sub>C<sub>i</sub></sub>(t)
                        <br><br>
                        <sup>R</sup>T<sub>E<sub>i</sub></sub><sup>des</sup>(t) = <sup>V</sup>ΔT<sub>C<sub>i</sub></sub>(t) <sup>R</sup>T<sub>E<sub>i</sub></sub><sup>0</sup>
                        <div class="formula-explanation">
                            Motion retargeting: compute relative controller motion and translate to desired robot end-effector pose
                        </div>
                    </div>
                </div>

                <p>
                    For each arm <em>i</em>, we solve a safety-aware inverse kinematics optimization at every control step:
                </p>
                
                <div class="math-formula">
                    <div class="formula-box">
                        Δ<strong>q</strong><sub>i</sub> = arg min<sub>Δ<strong>q</strong></sub> (
                        ||J<sub>i</sub> Δ<strong>q</strong> - <strong>e</strong><sub>i</sub><sup>cart</sup>||² + 
                        ω<sub>q</sub> ||Δ<strong>q</strong> - Δ<strong>q</strong><sub>C<sub>i</sub></sub>||² + 
                        μ² ||Δ<strong>q</strong>||²)
                        <div class="formula-explanation">
                            Three-term optimization: Cartesian tracking + joint matching + damping
                        </div>
                    </div>
                </div>

                <h3 class="subsection-title">Null-Space Bimanual Coordination</h3>
                <p>
                    We exploit the redundancy of dual 7-DoF arms using null-space control for secondary objectives. The system selects the closest configuration from a set of optimal bimanual configurations Ω<sub>ref</sub>:
                </p>
                
                <div class="math-formula">
                    <div class="formula-box">
                        (q<sub>L</sub><sup>*</sup>, q<sub>R</sub><sup>*</sup>) = arg min<sub>(q<sub>L</sub><sup>(k)</sup>, q<sub>R</sub><sup>(k)</sup>) ∈ Ω<sub>ref</sub></sub> ||q<sub>L</sub><sup>(k)</sup> - q<sub>L</sub>||² + ||q<sub>R</sub><sup>(k)</sup> - q<sub>R</sub>||²
                        <br><br>
                        Δq<sub>i,null</sub> = k<sub>n</sub> (I - J<sub>i</sub><sup>†</sup> J<sub>i</sub>) (q<sub>i</sub><sup>*</sup> - q<sub>i</sub>)
                        <br><br>
                        Δq<sub>i</sub> ← Δq<sub>i</sub> + Δq<sub>i,null</sub>
                        <div class="formula-explanation">
                            Complete null-space control: select optimal configuration, compute null-space motion, and combine with primary task
                        </div>
                    </div>
                </div>

                <h3 class="subsection-title">Cost-Effective Haptic Feedback</h3>
                <p>
                    Both kinesthetic and vibrotactile feedback are generated using joint current measurements. By subtracting precomputed gravity torques, the system isolates net interaction torques caused by contact or payload. This torque is rendered directly on the leader arm and mapped to vibration signals on VR controllers, creating a rich multimodal haptic interface without requiring expensive torque sensors.
                </p>
            </div>
        </section>

        <!-- Experimental Results -->
        <section class="section">
            <h2 class="section-title">Experimental Results</h2>
            <div class="section-content">
                <h3 class="subsection-title">Kitchen-Tidying Task</h3>
                <p>
                    We conducted a comprehensive user study with four participants performing a long-horizon bimanual manipulation task simulating a household kitchen-tidying routine. The task involves five sequential, contact-rich sub-tasks requiring dexterous coordination:
                </p>
                <ol>
                    <li><strong>Item Unpacking:</strong> Pick up assorted items from a cloth bag and place them on the table</li>
                    <li><strong>Shelf Organization:</strong> Sort and place items into designated positions in a multi-level kitchen shelf</li>
                    <li><strong>Towel Folding:</strong> Fold the towel neatly along a marked midline using both grippers</li>
                    <li><strong>Towel Placement:</strong> Place the folded towel onto the rack section of the shelf</li>
                    <li><strong>Clamp Attachment:</strong> Attach the clamp onto the rack to secure the towel in place</li>
                </ol>

                <h3 class="subsection-title">Performance Comparison</h3>
                <div class="results-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Method</th>
                                <th>Overall Success Rate</th>
                                <th>Completion Time (s)</th>
                                <th>Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>UniBiDex (VR)</strong></td>
                                <td>60% (24/40)</td>
                                <td>672 ± 20</td>
                                <td>+15% success, -18% time</td>
                            </tr>
                            <tr>
                                <td>Naive VR Baseline</td>
                                <td>45% (18/40)</td>
                                <td>816 ± 24</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td><strong>UniBiDex (Leader-Follower)</strong></td>
                                <td>75% (30/40)</td>
                                <td>319 ± 8</td>
                                <td>+18% success, -5% time</td>
                            </tr>
                            <tr>
                                <td>Naive LF Baseline</td>
                                <td>57% (24/40)</td>
                                <td>335 ± 9</td>
                                <td>-</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </section>

        <!-- Citation -->
        <section class="section">
            <h2 class="section-title">Citation</h2>
            <div class="section-content">
                <div class="citation-box">
                    <pre><code>@article{li2025unibidex,
    title   = {UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation},
    author  = {Zhongxuan Li and Zeliang Guo and Jun Hu and David Navarro-Alarcon and Jia Pan and Hongmin Wu and Peng Zhou},
    year    = {2025},
    journal = {2025 IEEE International Conference on Robotics and Biomimetics (IEEE ROBIO 2025)},
    note    = {Under Review},
    url     = {https://github.com/Dieselmarble/UniBiDex}
}</code></pre>
                </div>
            </div>
        </section>
    </div>

    <script src="script.js"></script>
</body>
</html>
